
<head>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" href="https://vanillacss.com/vanilla.css">

</head>
<body>
<div id="top" class="page" role="document">
\(
  \require{ams}
\DeclareMathOperator*{\softmax}{softmax}
\newcommand{\reals}[0]{\mathbb{R}}
\newcommand{\name}[1]{\mathsf{#1}}
\newcommand{\ndot}[1]{\mathbin{\mathop{\odot}_{\name{#1}}}}
\newcommand{\nsum}[1]{\mathbin{\mathop{\sum}_{\name{#1}}}}
\newcommand{\ntup}[2]{\name{#1}:#2}
\newcommand{\nfun}[2]{\underset{\name{#1}}{#2}}
\)

 <h1> Named Tensor Notation<h1>

  
  <h2> Attention</h2>  
\(
  \begin{align*} 
Q &\in \reals^{\ntup{key}{d_v},\ntup{time'}{n}}\\
K &\in \reals^{\ntup{head}{h},\ntup{key}{d_k}, \ntup{time}{n}}\\
V &\in \reals^{\ntup{head}{h}, \ntup{val}{d_v}, \ntup{time}{n}}\\
\text{attention}(Q, K, V) &=  \nfun{time}{\softmax} \left( \frac{Q \ndot{key} K }{\sqrt{d_k}} \right) \ndot{time} V 
\end{align*}
\)  
  
  <h2>MLP</h2>
  \(
   \begin{align*} 
V &\in \reals^{\ntup{output}{o}, \ntup{hidden}{h}},\ c\in \reals^{\ntup{output}{o}} \\
W &\in \reals^{{\ntup{hidden}{h}, \ntup{in}{i}}}, \ b \in \reals^{\ntup{hidden}{h}} \\
X &\in \reals^{{\ntup{batch}{b}, \ntup{in}{i}}} \\
\text{MLP}(X; V, W,b, c) &= \sigma \left( V \ndot{hidden} \sigma \left( W \ndot{in} X + b \right) + c \right)  
\end{align*}
   \)

<h2>NN Norms</h2>

   \(
   \begin{align*} 
X &\in \reals^{{\ntup{batch}{b}, \ntup{channel}{c}, \ntup{hidden}{h}}}\\
\gamma, \beta &\in \reals^{{\ntup{batch}{b}}} \\
\text{batchnorm}(X; \gamma, \beta) &= \frac{X - \nfun{batch}{\mathbb{E}}[X]}{\sqrt{\nfun{batch}{\text{var}}(X)} + \epsilon } \odot \gamma + \beta
\end{align*}

   \)
   </div>
   
</body>
